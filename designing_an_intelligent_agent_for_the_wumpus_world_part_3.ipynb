{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b747ab5d-9e6c-42ce-a107-6bddec57c31b",
   "metadata": {},
   "source": [
    "# Designing an Intelligent Agent for the Wumpus World - Part 3\n",
    "\n",
    "The Wumpus World is a classic problem in artificial intelligence that involves designing an agent to navigate a grid-based environment filled with hazards, such as pits and a fearsome Wumpus, while searching for gold. The agent must operate under uncertainty, leveraging logical reasoning and perception to make decisions in a partially observable world.\n",
    "\n",
    "This project focuses on implementing an intelligent Wumpus World agent capable of:\n",
    "Perceiving environmental cues such as breezes (near pits) and stenches (near the Wumpus).\n",
    "Applying logical inference to deduce the safe path to the gold.\n",
    "\n",
    "Balancing exploration and caution to avoid fatal encounters.\n",
    "\n",
    "The project highlights key AI concepts, including decision-making under uncertainty, logical reasoning, and search algorithms, providing a practical application of intelligent agent design in a challenging and dynamic environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac63f464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from enum import Enum, auto\n",
    "import networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy\n",
    "import torch\n",
    "from pomegranate.distributions import Categorical\n",
    "from pomegranate.distributions import ConditionalCategorical\n",
    "from pomegranate.bayesian_network import BayesianNetwork\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b439bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Percept():\n",
    "    time_step: int\n",
    "    bump: bool\n",
    "    breeze: bool\n",
    "    stench: bool\n",
    "    scream: bool\n",
    "    glitter: bool\n",
    "    reward: int\n",
    "    done: bool\n",
    "        \n",
    "    def __init__(self, time_step: int, bump: bool, breeze: bool, stench: bool, scream: bool, glitter: bool, reward: bool, done: bool):\n",
    "         self.time_step = time_step\n",
    "         self.bump = bump\n",
    "         self.breeze = breeze\n",
    "         self.stench = stench\n",
    "         self.scream = scream\n",
    "         self.glitter = glitter\n",
    "         self.reward = reward\n",
    "         self.done = done\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\\ntime_step: {self.time_step}\\nbump: {self.bump}\\nstench: {self.stench}\\nbreeze: {self.breeze}\\nscream: {self.scream}\\nglitter: {self.glitter}\\nreward: {self.reward}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39dc5f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    FORWARD = 2\n",
    "    GRAB = 3\n",
    "    SHOOT = 4\n",
    "    CLIMB = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cb67cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Orientation(Enum):\n",
    "    E = 0\n",
    "    S = 1\n",
    "    W = 2\n",
    "    N = 3\n",
    "\n",
    "    def symbol(self) -> str:\n",
    "        if self == Orientation.E:\n",
    "            return \">\"\n",
    "        elif self == Orientation.S:\n",
    "            return \"v\"\n",
    "        elif self == Orientation.W:\n",
    "            return \"<\"\n",
    "        elif self == Orientation.N:\n",
    "            return \"^\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "\n",
    "    def turn_right(self) -> 'Orientation':\n",
    "        current_index = self.value\n",
    "        next_index = (current_index + 1) % len(Orientation)\n",
    "        return Orientation(next_index)\n",
    "        \n",
    "    def turn_left(self) -> 'Orientation':\n",
    "        current_index = self.value\n",
    "        prev_index = (current_index - 1) % len(Orientation)\n",
    "        return Orientation(prev_index)\n",
    "    \n",
    "    def reverse(self) -> 'Orientation':\n",
    "        current_index = self.value\n",
    "        prev_index = (current_index + 2) % len(Orientation)\n",
    "        return Orientation(prev_index)\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self == Orientation.E:\n",
    "            return \"E\"\n",
    "        elif self == Orientation.S:\n",
    "            return \"S\"\n",
    "        elif self == Orientation.W:\n",
    "            return \"W\"\n",
    "        elif self == Orientation.N:\n",
    "            return \"N\"\n",
    "        else:\n",
    "            return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb7a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verbosity(Enum):\n",
    "    NONE = 0\n",
    "    LOGS = 1\n",
    "    ALL = 2\n",
    "\n",
    "class NaiveAgent:\n",
    "    verbosity: Verbosity\n",
    "    \n",
    "    def __init__(self, verbosity):\n",
    "        self.verbosity = verbosity\n",
    "    \n",
    "    def choose_action(self):\n",
    "        return random.choice(list(Action))\n",
    "    \n",
    "    def run(self):\n",
    "        env = Environment()\n",
    "        cumulative_reward = 0\n",
    "        percept = env.init(0.2, False)\n",
    "        while not percept.done:\n",
    "            if self.verbosity == Verbosity.ALL:\n",
    "                env.visualize()\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print('Percept:', percept)\n",
    "            action = self.choose_action()\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print()\n",
    "                print('Action:', action)\n",
    "                print()\n",
    "            percept = env.step(action)\n",
    "            cumulative_reward += percept.reward\n",
    "        if self.verbosity == Verbosity.ALL:\n",
    "            env.visualize()\n",
    "        if self.verbosity != Verbosity.NONE:\n",
    "            print('Percept:', percept)\n",
    "        print('Cumulative reward:', cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1fffcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Location:\n",
    "    x: int\n",
    "    y: int\n",
    "        \n",
    "    def __init__(self, x: int, y: int):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'({self.x}, {self.y})'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.x == other.x and self.y == other.y\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.x, self.y))\n",
    "    \n",
    "    def is_left_of(self, location: 'Location')->bool:\n",
    "        return self.x == location.x-1 and self.y == location.y\n",
    "        \n",
    "   \n",
    "    def is_right_of(self, location: 'Location')->bool:\n",
    "        return self.x == location.x+1 and self.y == location.y\n",
    "        \n",
    "    \n",
    "    def is_above(self, location: 'Location')->bool:\n",
    "        return self.x == location.x and self.y == location.y+1\n",
    "        \n",
    "    \n",
    "    def is_below(self, location: 'Location')->bool:\n",
    "        return self.x == location.x and self.y == location.y-1\n",
    "        \n",
    "    \n",
    "    def neighbours(self)->List['Location']:\n",
    "        return (Location(self.x-1, self.y), Location(self.x+1, self.y), Location(self.x, self.y+1), Location(self.x, self.y-1))\n",
    "    \n",
    "    \n",
    "    # return True if location given is self's location\n",
    "    def is_location(self, location: 'Location')->bool:\n",
    "        return self.x == location.x and self.y == location.y\n",
    "    \n",
    "    \n",
    "    def at_left_edge(self) -> bool:\n",
    "        return self.x == 1\n",
    "    \n",
    "    \n",
    "    def at_right_edge(self) -> bool:\n",
    "        # if not 4x4, we need to specify the width and height.\n",
    "        return self.x == 4\n",
    "    \n",
    "    \n",
    "    def at_top_edge(self) -> bool:\n",
    "        # if not 4x4, we need to specify the width and height.\n",
    "        return self.y == 4  \n",
    "    \n",
    "   \n",
    "    def at_bottom_edge(self) -> bool:\n",
    "        return self.y == 1  \n",
    "    \n",
    "    def is_edge(self):\n",
    "        return self.at_left_edge() or self.at_right_edge() or self.at_top_edge() or self.at_bottom_edge()\n",
    "    \n",
    "    def is_corner(self):\n",
    "        return (self.x==1 and self.y==1) or (self.x==1 and self.y==4) or (self.x==4 and self.y==1) or (self.x==4 and self.y==4)\n",
    "    \n",
    "    def get_edge_count(self):\n",
    "        if self.is_corner():\n",
    "            return 2\n",
    "        elif self.is_edge():\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    \n",
    "    def forward(self, orientation) -> bool:\n",
    "        if orientation == Orientation.N:\n",
    "            self.y += 1\n",
    "        elif orientation == Orientation.W:\n",
    "            self.x -= 1\n",
    "        elif orientation == Orientation.S:\n",
    "            self.y -= 1\n",
    "        elif orientation == Orientation.E:\n",
    "            self.x += 1\n",
    "        \n",
    "        if self.x < 1:\n",
    "            self.x = 1\n",
    "            return True\n",
    "        elif self.x > 4:\n",
    "            self.x = 4\n",
    "            return True\n",
    "        \n",
    "        if self.y < 1:\n",
    "            self.y = 1\n",
    "            return True\n",
    "        elif self.y > 4:\n",
    "            self.y = 4\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def set_to(self, location: 'Location'):\n",
    "        self.x = location.x\n",
    "        self.y = location.y\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def from_linear(n: int) -> 'Location':\n",
    "        pass\n",
    "        # convert an index from 0 to 15 to a location\n",
    "    \n",
    "    \n",
    "    def to_linear(self)->int:\n",
    "        pass\n",
    "        # convert self to an index from 0 to 15    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def random() -> 'Location':\n",
    "        x = random.randint(1, 4)\n",
    "        y = random.randint(1, 4)\n",
    "        return Location(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9150c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    wumpus_location: Location\n",
    "    wumpus_alive: bool\n",
    "    agent_location: Location\n",
    "    agent_orientation: Orientation\n",
    "    agent_has_arrow: bool\n",
    "    agent_has_gold: bool\n",
    "    game_over: bool\n",
    "    gold_location: Location\n",
    "    pit_locations: List[Location]\n",
    "    time_step: int\n",
    "    allow_climb_without_gold: bool\n",
    "        \n",
    "    def init(self, pit_prob: float, allow_climb_without_gold: bool):\n",
    "        self.make_wumpus()\n",
    "        self.make_gold()\n",
    "        self.pit_locations = []\n",
    "        self.make_pits(pit_prob)\n",
    "        \n",
    "        self.agent_location = Location(1,1)\n",
    "        self.agent_orientation = Orientation.E\n",
    "        self.agent_has_arrow = True\n",
    "        self.agent_has_gold = False\n",
    "        \n",
    "        self.game_over = False\n",
    "        self.time_step = 0\n",
    "        self.allow_climb_without_gold = allow_climb_without_gold\n",
    "        return Percept(self.time_step, False, self.is_breeze(), self.is_stench(), False, self.is_glitter(), 0, self.game_over)\n",
    "         \n",
    "        \n",
    "    def get_random_location(self):\n",
    "        temp_loc = None\n",
    "        while True:\n",
    "            temp_loc = Location.random()\n",
    "            if not (temp_loc.x == 1 and temp_loc.y == 1):\n",
    "                break\n",
    "        return temp_loc\n",
    "            \n",
    "    def make_wumpus(self):\n",
    "        self.wumpus_location = self.get_random_location()\n",
    "        self.wumpus_alive = True\n",
    " \n",
    "    def make_gold(self):\n",
    "        self.gold_location = self.get_random_location()\n",
    "\n",
    "    def make_pits(self, pit_prob: float):\n",
    "        for y in range(1,5):\n",
    "            for x in range(1,5):\n",
    "                if x == 1 and y == 1:\n",
    "                    pass\n",
    "                elif random.random() <= pit_prob:\n",
    "                    self.pit_locations.append(Location(x, y))\n",
    " \n",
    "    def is_pit_at(self, location: Location) -> bool:\n",
    "        if location in self.pit_locations:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_pit_adjacent_to_agent(self) -> bool:\n",
    "        for neighbor in self.agent_location.neighbours():\n",
    "            if neighbor in self.pit_locations:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_wumpus_adjacent_to_agent(self) -> bool:\n",
    "        if self.wumpus_location in self.agent_location.neighbours():\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def is_agent_at_hazard(self)->bool:\n",
    "        if self.agent_location is self.wumpus_location or\\\n",
    "            self.agent_location in self.pit_locations:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_wumpus_at(self, location: Location) -> bool:\n",
    "        return self.wumpus_location == location\n",
    "        \n",
    "    def is_agent_at(self, location: Location) -> bool:\n",
    "        return self.agent_location == location \n",
    "    \n",
    "    def is_gold_at(self, location: Location) -> bool:\n",
    "        return self.gold_location == location\n",
    "        \n",
    "    def is_glitter(self) -> bool:\n",
    "        return self.agent_location == self.gold_location\n",
    "        \n",
    "    def is_breeze(self) -> bool:\n",
    "        if self.agent_location in self.pit_locations:\n",
    "            return True\n",
    "        for neighbor in self.agent_location.neighbours():\n",
    "            if neighbor in self.pit_locations:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_stench(self) -> bool:\n",
    "        if self.agent_location == self.wumpus_location:\n",
    "            return True\n",
    "        for neighbor in self.agent_location.neighbours():\n",
    "            if neighbor == self.wumpus_location:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def wumpus_in_line_of_fire(self) -> bool:\n",
    "        line_of_fire = []\n",
    "        if self.agent_orientation == Orientation.N:\n",
    "            if self.agent_location.y < 4:\n",
    "                for y in range(self.agent_location.y, 5):\n",
    "                    line_of_fire.append(Location(self.agent_location.x, y))\n",
    "        if self.agent_orientation == Orientation.S:\n",
    "            if self.agent_location.y > 1:\n",
    "                for y in range(self.agent_location.y, 0, -1):\n",
    "                    line_of_fire.append(Location(self.agent_location.x, y))\n",
    "        if self.agent_orientation == Orientation.E:\n",
    "            if self.agent_location.x < 4:\n",
    "                for x in range(self.agent_location.x, 5):\n",
    "                    line_of_fire.append(Location(x, self.agent_location.y))\n",
    "        if self.agent_orientation == Orientation.W:\n",
    "            if self.agent_location.x > 1:\n",
    "                for x in range(self.agent_location.x, 0, -1):\n",
    "                    line_of_fire.append(Location(x, self.agent_location.y))\n",
    "                    \n",
    "        if self.wumpus_location in line_of_fire:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def kill_attempt(self) -> bool:\n",
    "        if self.wumpus_in_line_of_fire() and self.wumpus_alive:\n",
    "            self.wumpus_alive = False\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def step(self, action: Action) -> Percept:\n",
    "        bump = False\n",
    "        scream = False\n",
    "        reward = -1\n",
    "        if action == Action.FORWARD:\n",
    "            bump = self.agent_location.forward(self.agent_orientation)\n",
    "            if self.agent_has_gold:\n",
    "                self.gold_location = self.agent_location\n",
    "            if self.is_wumpus_at(self.agent_location) and self.wumpus_alive:\n",
    "                reward -= 1000\n",
    "                self.game_over = True\n",
    "            if self.is_pit_at(self.agent_location) and not self.game_over:\n",
    "                reward -= 1000\n",
    "                self.game_over = True\n",
    "        if action == Action.SHOOT and self.agent_has_arrow:\n",
    "            reward -= 10\n",
    "            scream = self.kill_attempt()\n",
    "            self.agent_has_arrow = False\n",
    "        if action == Action.CLIMB:\n",
    "            if self.agent_location == Location(1,1):\n",
    "                if self.allow_climb_without_gold:\n",
    "                    self.game_over = True\n",
    "                if self.agent_has_gold:\n",
    "                    self.game_over = True\n",
    "                    reward += 1000\n",
    "        if action == Action.LEFT:\n",
    "            self.agent_orientation = self.agent_orientation.turn_left()\n",
    "        if action == Action.RIGHT:\n",
    "            self.agent_orientation = self.agent_orientation.turn_right()\n",
    "        if action == Action.GRAB and self.is_gold_at(self.agent_location):\n",
    "            self.agent_has_gold = True\n",
    "        \n",
    "        self.time_step += 1\n",
    "        return Percept(self.time_step, bump, self.is_breeze(), self.is_stench(), scream, self.is_glitter(), reward, self.game_over)\n",
    "    \n",
    "    # Visualize the game state\n",
    "    def visualize(self):\n",
    "        for y in range(3, -1, -1):\n",
    "            line = '|'\n",
    "            for x in range(0, 4):\n",
    "                loc = Location(x+1, y+1)\n",
    "                cell_symbols = [' ', ' ', ' ', ' ']\n",
    "                if self.is_agent_at(loc): cell_symbols[0] = self.agent_orientation.symbol()\n",
    "                if self.is_pit_at(loc): cell_symbols[1] = 'P'\n",
    "                if self.is_wumpus_at(loc):\n",
    "                    if self.wumpus_alive:\n",
    "                        cell_symbols[2] = 'W'\n",
    "                    else:\n",
    "                        cell_symbols[2] = 'w'\n",
    "                if self.is_gold_at(loc): cell_symbols[3] = 'G'\n",
    "                for char in cell_symbols: line += char\n",
    "                line += '|'\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890c1e08-c928-4981-a991-68535db3ba11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    location: Location\n",
    "    orientation: Orientation\n",
    "        \n",
    "    def __init__(self, location, orientation):\n",
    "        self.location = location\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.location == other.location and self.orientation == other.orientation\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"X: {self.location.x} Y: {self.location.y} Or: {self.orientation}\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.location, self.orientation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733a4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotSoNaiveAgent():\n",
    "    verbosity: Verbosity\n",
    "    has_gold: bool\n",
    "    actions_to_victory: list\n",
    "        \n",
    "    def __init__(self, verbosity):\n",
    "        self.has_gold = False\n",
    "        self.verbosity = verbosity\n",
    "        self.nodes = set()\n",
    "        self.actions_to_victory = []\n",
    "        self.graph = networkx.DiGraph()\n",
    "            \n",
    "    def add_new_nodes(self, location, was_forward, orientation):\n",
    "        # Here we add all 4 orientations of a new location as node to the graph and nodes list\n",
    "        # when we visit for the location for the first time\n",
    "        newly_added_nodes = []\n",
    "        for orient in Orientation:\n",
    "            new_node = Node(location, orient)\n",
    "            if new_node not in self.nodes:\n",
    "                newly_added_nodes.append(new_node)\n",
    "                self.nodes.add(new_node)\n",
    "                self.graph.add_node(new_node, label=f\"{new_node.location.x}, {new_node.location.y}, {new_node.orientation}\")\n",
    "                \n",
    "        # Here we are adding edges between the connected rotations of the same location\n",
    "        for new_node in newly_added_nodes:\n",
    "            left_node = Node(location, new_node.orientation.turn_left())\n",
    "            right_node = Node(location, new_node.orientation.turn_right())\n",
    "            if left_node in self.nodes:\n",
    "                self.graph.add_edge(new_node, left_node)\n",
    "                self.graph.add_edge(left_node, new_node)\n",
    "            if right_node in self.nodes:\n",
    "                self.graph.add_edge(new_node, right_node)\n",
    "                self.graph.add_edge(right_node, new_node)\n",
    "        \n",
    "        \"\"\"If agent moved forward on the previous action, we are going to add a new edge\n",
    "        between the previous node and the current one of the same orientation. ie. if agent\n",
    "        moved from 1,1,E to 2,1,E.\n",
    "        \n",
    "        We are also adding a reversed path edge between the new location of reversed\n",
    "        orientation and old location of reversed orientation such as if you moved from node\n",
    "        1,1,E to 2,1,E we add a new edge from 2,1,W to 1,1,W\n",
    "        \"\"\"\n",
    "        if was_forward:\n",
    "            current_node = Node(location, orientation)\n",
    "            previous_location = None\n",
    "            if orientation == Orientation.E and location.x-1 > 0:\n",
    "                previous_location = Location(location.x-1, location.y)\n",
    "            elif orientation == Orientation.N and location.y-1 > 0:\n",
    "                previous_location = Location(location.x, location.y-1)\n",
    "            elif orientation == Orientation.W and location.x+1 < 5:\n",
    "                previous_location = Location(location.x+1, location.y)\n",
    "            elif orientation == Orientation.S and location.y+1 < 5:\n",
    "                previous_location = Location(location.x, location.y+1)\n",
    "            if previous_location:\n",
    "                previous_node = Node(previous_location, orientation)\n",
    "                new_node = None\n",
    "                for node in self.nodes:\n",
    "                    if node.location == location and node.orientation == orientation:\n",
    "                        new_node = node\n",
    "                        break\n",
    "                if previous_node in self.nodes and new_node:\n",
    "                    self.graph.add_edge(previous_node, new_node)\n",
    "\n",
    "                reversed_previous_node = None\n",
    "                reversed_new_node = None\n",
    "                if Node(new_node.location, new_node.orientation.reverse()) in self.nodes:\n",
    "                    reversed_new_node = Node(new_node.location, new_node.orientation.reverse())\n",
    "                if Node(previous_node.location, previous_node.orientation.reverse()) in self.nodes:\n",
    "                    reversed_previous_node = Node(previous_node.location, previous_node.orientation.reverse())\n",
    "                if reversed_previous_node and reversed_new_node:\n",
    "                    self.graph.add_edge(reversed_new_node, reversed_previous_node)\n",
    "                        \n",
    "            # Let's add edges between visited neighboring nodes.\n",
    "            neighbors = []\n",
    "            if location.x + 1 < 5:\n",
    "                neighbors.append(Node(Location(location.x+1, location.y), Orientation.E))\n",
    "            if location.y + 1 < 5:\n",
    "                neighbors.append(Node(Location(location.x, location.y+1), Orientation.N))\n",
    "            if location.x - 1 > 0:\n",
    "                neighbors.append(Node(Location(location.x-1, location.y), Orientation.W))\n",
    "            if location.y - 1 > 0:\n",
    "                neighbors.append(Node(Location(location.x, location.y-1), Orientation.S))\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor in self.nodes:\n",
    "                    if neighbor.orientation == Orientation.E:\n",
    "                        self.graph.add_edge(Node(location, Orientation.E), neighbor)\n",
    "                        self.graph.add_edge(Node(neighbor.location, Orientation.W), Node(location, Orientation.W))\n",
    "                    elif neighbor.orientation == Orientation.W:\n",
    "                        self.graph.add_edge(Node(location, Orientation.W), neighbor)\n",
    "                        self.graph.add_edge(Node(neighbor.location, Orientation.E), Node(location, Orientation.E))\n",
    "                    elif neighbor.orientation == Orientation.N:\n",
    "                        self.graph.add_edge(Node(location, Orientation.N), neighbor)\n",
    "                        self.graph.add_edge(Node(neighbor.location, Orientation.S), Node(location, Orientation.S))\n",
    "                    elif neighbor.orientation == Orientation.S:\n",
    "                        self.graph.add_edge(Node(location, Orientation.S), neighbor)\n",
    "                        self.graph.add_edge(Node(neighbor.location, Orientation.N), Node(location, Orientation.N))\n",
    "            \n",
    "        \n",
    "    def draw_graph(self):\n",
    "        if (self.verbosity == Verbosity.NONE):\n",
    "            return\n",
    "        pos = networkx.spring_layout(self.graph)  # positions for all nodes\n",
    "        networkx.draw(self.graph, pos, with_labels=True, labels={node: str(node) for node in self.graph.nodes}, node_color='skyblue', node_size=500, edge_color='gray')\n",
    "        plt.show()\n",
    "            \n",
    "    def choose_action(self):\n",
    "        return random.choice([Action.LEFT, Action.RIGHT, Action.FORWARD])\n",
    "    \n",
    "    def find_actions_to_victory(self, current_node, nodes):\n",
    "        self.actions_to_victory = []\n",
    "        for node in nodes:\n",
    "            if node == current_node:\n",
    "                continue\n",
    "                \n",
    "            if Node(current_node.location, current_node.orientation.turn_left()) == node:\n",
    "                self.actions_to_victory.append(Action.LEFT)\n",
    "            elif Node(current_node.location, current_node.orientation.turn_right()) == node:\n",
    "                self.actions_to_victory.append(Action.RIGHT)\n",
    "            else:\n",
    "                self.actions_to_victory.append(Action.FORWARD)\n",
    "                \n",
    "            current_node = node\n",
    "                \n",
    "            if current_node.location == Location(1,1):\n",
    "                self.actions_to_victory.append(Action.CLIMB)\n",
    "                break\n",
    "    \n",
    "    def manhattan_distance(self, node1, node2):\n",
    "        return abs(node1.location.x - node2.location.x) + abs(node1.location.y - node2.location.y)\n",
    "            \n",
    "    def run(self):\n",
    "        env = Environment()\n",
    "        cumulative_reward = 0\n",
    "        percept = env.init(0.2, False)\n",
    "        was_forward = False\n",
    "        while not percept.done:\n",
    "            action = None\n",
    "            self.add_new_nodes(Location(env.agent_location.x, env.agent_location.y), was_forward, env.agent_orientation)\n",
    "            if self.verbosity == Verbosity.ALL:\n",
    "                env.visualize()\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print('Percept:', percept)\n",
    "            if len(self.actions_to_victory):\n",
    "                action = self.actions_to_victory.pop(0)\n",
    "            else:\n",
    "                if percept.glitter and not self.has_gold:\n",
    "                    action = Action.GRAB\n",
    "                    self.has_gold = True\n",
    "                    target_node = Node(Location(1, 1), Orientation.W)\n",
    "                    current_node = Node(env.agent_location, env.agent_orientation)\n",
    "                    self.find_actions_to_victory(current_node, networkx.astar_path(self.graph, current_node, target_node, heuristic=self.manhattan_distance))\n",
    "                elif self.has_gold and env.agent_location.is_location(Location(1,1)):\n",
    "                    action = Action.CLIMB\n",
    "                else:\n",
    "                    action = self.choose_action()\n",
    "            \n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print()\n",
    "                print('Action:', action)\n",
    "                print()\n",
    "            percept = env.step(action)\n",
    "            if action == Action.FORWARD and not percept.bump:\n",
    "                was_forward = True\n",
    "            else:\n",
    "                was_forward = False\n",
    "            cumulative_reward += percept.reward\n",
    "        if self.verbosity == Verbosity.ALL:\n",
    "            env.visualize()\n",
    "            self.draw_graph()\n",
    "        if self.verbosity != Verbosity.NONE:\n",
    "            print('Percept:', percept)\n",
    "        print('Cumulative reward:', cumulative_reward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee69a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate():   \n",
    "    def __init__(self, prob: float):\n",
    "        self.p = prob\n",
    "        \n",
    "    def toList(self):\n",
    "        return [1-self.p, self.p]\n",
    "        \n",
    "    def toCategorical(self):\n",
    "        return Categorical([self.toList()])\n",
    "\n",
    "class ProbAgent(NotSoNaiveAgent):\n",
    "    pits = {}\n",
    "    breezes = {}\n",
    "    breeze_model = None\n",
    "    heard_scream = False\n",
    "    visited_locations = {}\n",
    "    stenches = []\n",
    "    wumpus_probs = []\n",
    "    wumpus_alert = False\n",
    "    stench_model = None\n",
    "    pit_probs = []\n",
    "    fully_explored_locations = {}\n",
    "    risk_tolerance = 0.4\n",
    "    \n",
    "    def __init__(self, verbosity):\n",
    "        self.pits = {}\n",
    "        self.breezes = {}\n",
    "        self.heard_scream = False\n",
    "        self.visited_locations = {}\n",
    "        self.stenches = []\n",
    "        self.wumpus_probs = []\n",
    "        self.wumpus_alert = False\n",
    "        self.stench_model = None\n",
    "        self.pit_probs = []\n",
    "        self.fully_explored_locations = {}\n",
    "        self.risk_tolerance = 0.4\n",
    "        super().__init__(verbosity)\n",
    "        for x in range(1,5):\n",
    "            for y in range(1,5):\n",
    "                if x == 1 and y == 1:\n",
    "                    self.pits[\"11\"] = Predicate(0.0).toCategorical()\n",
    "                    self.visited_locations[\"11\"] = True\n",
    "                    self.fully_explored_locations[\"11\"] = False\n",
    "                    self.stenches.append(-1)\n",
    "                    self.wumpus_probs.append(0)\n",
    "                else:\n",
    "                    self.pits[f\"{x}{y}\"] = Predicate(0.2).toCategorical()\n",
    "                    self.visited_locations[f\"{x}{y}\"] = False\n",
    "                    self.stenches.append(-1)\n",
    "                    self.wumpus_probs.append(1./15)\n",
    "    \n",
    "    def generate_conditional_table(self, neighbor_count):\n",
    "        table = []\n",
    "        combis = []\n",
    "\n",
    "        # Generate all possible combinations of neighbor states (False/True)\n",
    "        for combination in product([False, True], repeat=neighbor_count):\n",
    "            # breeze is true if any neighbor is pit\n",
    "            if any(combination):\n",
    "                combis.append(Predicate(1.0).toList())\n",
    "            else:\n",
    "                combis.append(Predicate(0.0).toList())\n",
    "\n",
    "        if len(combis) == 4:\n",
    "            table.append([combis[0], combis[1]])\n",
    "            table.append([combis[2], combis[3]])\n",
    "        elif len(combis) == 8:\n",
    "            table.append([[combis[0], combis[1]], [combis[2], combis[3]]])\n",
    "            table.append([[combis[4], combis[5]], [combis[6], combis[7]]])\n",
    "        elif len(combis) == 16:\n",
    "            table.append([[[combis[0], combis[1]], [combis[2], combis[3]]], [[combis[4], combis[5]], [combis[6], combis[7]]]])\n",
    "            table.append([[[combis[8], combis[9]], [combis[10], combis[11]]], [[combis[12], combis[13]], [combis[14], combis[15]]]])\n",
    "\n",
    "        return [table]\n",
    "\n",
    "    def update_breeze(self, x, y, percept, edge_count):\n",
    "        # We came to this location and we are alive means no pit here.\n",
    "        self.pits[f\"{x}{y}\"] = Predicate(0.0).toCategorical()\n",
    "        self.visited_locations[f\"{x}{y}\"] = True\n",
    "        # If we don't have breeze on this location, it means none of our neighbors has pit\n",
    "        if not percept.breeze:\n",
    "            if x > 1:\n",
    "                self.pits[f\"{x - 1}{y}\"] = Predicate(0.0).toCategorical()\n",
    "            if x < 4:\n",
    "                self.pits[f\"{x + 1}{y}\"] = Predicate(0.0).toCategorical()\n",
    "            if y > 1:\n",
    "                self.pits[f\"{x}{y - 1}\"] = Predicate(0.0).toCategorical()\n",
    "            if y < 4:\n",
    "                self.pits[f\"{x}{y + 1}\"] = Predicate(0.0).toCategorical()\n",
    "                    \n",
    "                    \n",
    "        if f\"{x}{y}\" not in self.breezes.keys():\n",
    "            self.breezes[f\"{x}{y}\"] = None\n",
    "        self.breezes[f\"{x}{y}\"] = ConditionalCategorical(self.generate_conditional_table(edge_count))\n",
    "    \n",
    "    def build_bayesian_network(self, current_x, current_y):\n",
    "        # Initialize variables for the Bayesian network\n",
    "        variables = []\n",
    "        edges = []\n",
    "\n",
    "        # Check the current breeze location and relevant pits\n",
    "        breeze_key = f\"{current_x}{current_y}\"\n",
    "        if breeze_key in self.breezes.keys():\n",
    "            # Check neighboring positions for pits\n",
    "            neighbors = []\n",
    "            if current_x > 1:  # Left\n",
    "                neighbor_key = f\"{current_x - 1}{current_y}\"\n",
    "                if neighbor_key in self.pits.keys():\n",
    "                    neighbors.append(self.pits[neighbor_key])\n",
    "                    variables.append(self.pits[neighbor_key])  # Add pit variable\n",
    "            if current_y < 4:  # Up\n",
    "                neighbor_key = f\"{current_x}{current_y + 1}\"\n",
    "                if neighbor_key in self.pits.keys():\n",
    "                    neighbors.append(self.pits[neighbor_key])\n",
    "                    variables.append(self.pits[neighbor_key])  # Add pit variable\n",
    "            if current_x < 4:  # Right\n",
    "                neighbor_key = f\"{current_x + 1}{current_y}\"\n",
    "                if neighbor_key in self.pits.keys():\n",
    "                    neighbors.append(self.pits[neighbor_key])\n",
    "                    variables.append(self.pits[neighbor_key])  # Add pit variable\n",
    "            if current_y > 1:  # Down\n",
    "                neighbor_key = f\"{current_x}{current_y - 1}\"\n",
    "                if neighbor_key in self.pits.keys():\n",
    "                    neighbors.append(self.pits[neighbor_key])\n",
    "                    variables.append(self.pits[neighbor_key])  # Add pit variable\n",
    "                    \n",
    "            # Add the current breeze variable to the variables list\n",
    "            variables.append(self.breezes[breeze_key])\n",
    "\n",
    "            # Create edges between the breeze and its relevant neighboring pits\n",
    "            for neighbor in neighbors:\n",
    "                edges.append((neighbor, self.breezes[breeze_key]))\n",
    "\n",
    "        # Build the Bayesian network with the filtered variables and edges\n",
    "        return BayesianNetwork(variables, edges)\n",
    "        \n",
    "    def build_query(self, x, y, percept):\n",
    "        query = []\n",
    "\n",
    "        # Check bounds for neighbors\n",
    "        if x > 1: # left neighbor\n",
    "            if self.pits[f\"{x - 1}{y}\"].probs[0][1] == 0:\n",
    "                query.append(0)\n",
    "            elif self.pits[f\"{x - 1}{y}\"].probs[0][1] == 1:\n",
    "                query.append(1)\n",
    "            else:\n",
    "                query.append(-1)\n",
    "                \n",
    "        if y < 4: # up neighbor\n",
    "            if self.pits[f\"{x}{y + 1}\"].probs[0][1] == 0:\n",
    "                query.append(0)\n",
    "            elif self.pits[f\"{x}{y + 1}\"].probs[0][1] == 1:\n",
    "                query.append(1)\n",
    "            else:\n",
    "                query.append(-1)\n",
    "                \n",
    "        if x < 4: # right neighbor\n",
    "            if self.pits[f\"{x + 1}{y}\"].probs[0][1] == 0:\n",
    "                query.append(0)\n",
    "            elif self.pits[f\"{x + 1}{y}\"].probs[0][1] == 1:\n",
    "                query.append(1)\n",
    "            else:\n",
    "                query.append(-1)\n",
    "\n",
    "        if y > 1: # down neighbor\n",
    "            if self.pits[f\"{x}{y - 1}\"].probs[0][1] == 0:\n",
    "                query.append(0)\n",
    "            elif self.pits[f\"{x}{y - 1}\"].probs[0][1] == 1:\n",
    "                query.append(1)\n",
    "            else:\n",
    "                query.append(-1)\n",
    "\n",
    "        if percept.breeze:\n",
    "            query.append(1)\n",
    "        else:\n",
    "            query.append(0)\n",
    "        return query\n",
    "\n",
    "    \n",
    "    def query_network(self, query):\n",
    "        X = torch.tensor([query])\n",
    "        X_masked = torch.masked.MaskedTensor(X, mask=X >= 0)\n",
    "        return self.breeze_model.predict_proba(X_masked)\n",
    "    \n",
    "    def get_index(self, x, y):\n",
    "        return (x-1)+(4*((y-1)%4))\n",
    "    \n",
    "    def update_stenches(self, x, y, percept):\n",
    "        for prob in self.wumpus_probs:\n",
    "            if prob == 1:\n",
    "                return\n",
    "        # We came to this location and we are alive means no wumpus here.\n",
    "        self.wumpus_probs[self.get_index(x,y)] = 0\n",
    "        \n",
    "        neighbors = []\n",
    "        if x > 1 and not self.visited_locations[f\"{x-1}{y}\"] and self.wumpus_probs[self.get_index(x-1, y)] > 0: # left neighbor\n",
    "            neighbors.append(self.get_index(x-1,y))\n",
    "        if x < 4 and not self.visited_locations[f\"{x+1}{y}\"] and self.wumpus_probs[self.get_index(x+1, y)] > 0: # right neighbor\n",
    "            neighbors.append(self.get_index(x+1,y))\n",
    "        if y > 1 and not self.visited_locations[f\"{x}{y-1}\"] and self.wumpus_probs[self.get_index(x, y-1)] > 0: # down neighbor\n",
    "            neighbors.append(self.get_index(x,y-1))\n",
    "        if y < 4 and not self.visited_locations[f\"{x}{y+1}\"] and self.wumpus_probs[self.get_index(x, y+1)] > 0: # up neighbor\n",
    "            neighbors.append(self.get_index(x,y+1))\n",
    "\n",
    "        if percept.stench:\n",
    "            self.stenches[self.get_index(x, y)] = 1\n",
    "            \n",
    "            # If we have stench on this location, it means only our neighbors have probability of \n",
    "            # having wumpus so we equally split 1 between them.\n",
    "            if x > 1 and self.wumpus_probs[self.get_index(x-1, y)] > 0:\n",
    "                self.wumpus_probs[self.get_index(x-1,y)] = 1/len(neighbors)\n",
    "            if x < 4 and self.wumpus_probs[self.get_index(x+1, y)] > 0:\n",
    "                self.wumpus_probs[self.get_index(x+1,y)] = 1/len(neighbors)\n",
    "            if y > 1 and self.wumpus_probs[self.get_index(x, y-1)] > 0:\n",
    "                self.wumpus_probs[self.get_index(x,y-1)] = 1/len(neighbors)\n",
    "            if y < 4 and self.wumpus_probs[self.get_index(x, y+1)] > 0:\n",
    "                self.wumpus_probs[self.get_index(x,y+1)] = 1/len(neighbors)\n",
    "                \n",
    "            # None of the not neighboring locations have possibility of having wumpus\n",
    "            for i in range(16):\n",
    "                if i not in neighbors:\n",
    "                    self.wumpus_probs[i] = 0\n",
    "        else:\n",
    "            self.stenches[self.get_index(x, y)] = 0\n",
    "\n",
    "            # If we don't have stench on this location, it means none of our neighbors has wumpus\n",
    "            if x > 1:\n",
    "                self.wumpus_probs[self.get_index(x-1,y)] = 0\n",
    "            if x < 4:\n",
    "                self.wumpus_probs[self.get_index(x+1,y)] = 0\n",
    "            if y > 1:\n",
    "                self.wumpus_probs[self.get_index(x,y-1)] = 0\n",
    "            if y < 4:\n",
    "                self.wumpus_probs[self.get_index(x,y+1)] = 0\n",
    "            \n",
    "            # We need to split the probability of having wumpus between the unvisited locations\n",
    "            # Not sure if this will have any effect but feels right to update it.\n",
    "            unsafe_count = 0\n",
    "            for i in range(16):\n",
    "                if self.wumpus_probs[i] > 0:\n",
    "                    unsafe_count += 1\n",
    "            for i in range(16):\n",
    "                if self.wumpus_probs[i] > 0:\n",
    "                    self.wumpus_probs[i] = 1/unsafe_count\n",
    "\n",
    "    def get_stench_probs(self, x, y):\n",
    "        indexes = []\n",
    "        if x > 1: # left\n",
    "            indexes.append(self.get_index(x-1,y))\n",
    "        if y < 4: # top\n",
    "            indexes.append(self.get_index(x,y+1))\n",
    "        if x < 4: # right\n",
    "            indexes.append(self.get_index(x+1,y))\n",
    "        if y > 1: # bottom\n",
    "            indexes.append(self.get_index(x,y-1))\n",
    "        probs = []\n",
    "        for _index in indexes:\n",
    "            probs.append(self.wumpus_probs[_index])\n",
    "        return probs\n",
    "    \n",
    "    def get_breeze_probs(self):\n",
    "        return [tensor[0, 1].item() for tensor in self.pit_probs[:-1]]\n",
    "        \n",
    "    def get_neighbors_probs(self, x ,y):\n",
    "        breezes = self.get_breeze_probs()\n",
    "        stenches = self.get_stench_probs(x, y)\n",
    "        for stench in stenches:\n",
    "            stench = 0\n",
    "        neighbor_count = 0\n",
    "        probs = []\n",
    "        \n",
    "        if x > 1: # left\n",
    "            if stenches[neighbor_count] >= 0.5:\n",
    "                self.wumpus_alert = True\n",
    "            probs.append(stenches[neighbor_count] + breezes[neighbor_count] - (stenches[neighbor_count]*breezes[neighbor_count]))\n",
    "            if breezes[neighbor_count] == 1:\n",
    "                self.fully_explored_locations[f\"{x-1}{y}\"] = True\n",
    "            neighbor_count += 1\n",
    "        if y < 4: # top\n",
    "            if stenches[neighbor_count] >= 0.5:\n",
    "                self.wumpus_alert = True\n",
    "            probs.append(stenches[neighbor_count] + breezes[neighbor_count] - (stenches[neighbor_count]*breezes[neighbor_count]))\n",
    "            if breezes[neighbor_count] == 1:\n",
    "                self.fully_explored_locations[f\"{x}{y+1}\"] = True\n",
    "            neighbor_count += 1\n",
    "        if x < 4: # right\n",
    "            if stenches[neighbor_count] >= 0.5:\n",
    "                self.wumpus_alert = True\n",
    "            probs.append(stenches[neighbor_count] + breezes[neighbor_count] - (stenches[neighbor_count]*breezes[neighbor_count]))\n",
    "            if breezes[neighbor_count] == 1:\n",
    "                self.fully_explored_locations[f\"{x+1}{y}\"] = True\n",
    "            neighbor_count += 1\n",
    "        if y > 1: # bottom\n",
    "            if stenches[neighbor_count] >= 0.5:\n",
    "                self.wumpus_alert = True\n",
    "            probs.append(stenches[neighbor_count] + breezes[neighbor_count] - (stenches[neighbor_count]*breezes[neighbor_count]))\n",
    "            if breezes[neighbor_count] == 1:\n",
    "                self.fully_explored_locations[f\"{x}{y-1}\"] = True\n",
    "            neighbor_count += 1\n",
    "            \n",
    "        is_explored = True\n",
    "        neighbor_count = 0\n",
    "        if x > 1 and not self.visited_locations[f\"{x-1}{y}\"] and probs[neighbor_count] <= self.risk_tolerance:\n",
    "            is_explored = False\n",
    "        elif x > 1:\n",
    "            neighbor_count += 1\n",
    "        \n",
    "        if y < 4 and not self.visited_locations[f\"{x}{y+1}\"] and probs[neighbor_count] <= self.risk_tolerance:\n",
    "            is_explored = False\n",
    "        elif y < 4:\n",
    "            neighbor_count += 1\n",
    "        \n",
    "        if x < 4 and not self.visited_locations[f\"{x+1}{y}\"] and probs[neighbor_count] <= self.risk_tolerance:\n",
    "            is_explored = False\n",
    "        elif x < 4:\n",
    "            neighbor_count += 1\n",
    "            \n",
    "        if y > 1 and not self.visited_locations[f\"{x}{y-1}\"] and probs[neighbor_count] <= self.risk_tolerance:\n",
    "            is_explored = False\n",
    "        elif y > 1:\n",
    "            neighbor_count += 1\n",
    "            \n",
    "        if is_explored:\n",
    "            self.fully_explored_locations[f\"{x}{y}\"] = True\n",
    "        elif f\"{x}{y}\" not in self.fully_explored_locations.keys():\n",
    "            self.fully_explored_locations[f\"{x}{y}\"] = False\n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def where_to_go(self, x, y, probs, is_stuck = False):\n",
    "        is_left = False\n",
    "        is_top = False\n",
    "        is_right = False\n",
    "        is_bottom = False\n",
    "        neighbor_count = 0\n",
    "        neighbor_coordinates = []\n",
    "        min_prob = self.risk_tolerance\n",
    "\n",
    "        if x > 1:\n",
    "            if probs[neighbor_count] < min_prob:\n",
    "                if not is_stuck and not self.visited_locations[f\"{x-1}{y}\"] or (is_stuck and not self.fully_explored_locations[f\"{x-1}{y}\"]):\n",
    "                    min_prob = probs[neighbor_count]\n",
    "                    is_left = True\n",
    "            neighbor_count += 1\n",
    "            neighbor_coordinates.append([x-1,y])\n",
    "        \n",
    "        if y < 4:\n",
    "            if probs[neighbor_count] < min_prob:\n",
    "                if not is_stuck and not self.visited_locations[f\"{x}{y+1}\"] or (is_stuck and not self.fully_explored_locations[f\"{x}{y+1}\"]):\n",
    "                    min_prob = probs[neighbor_count]\n",
    "                    is_left = False\n",
    "                    is_top = True\n",
    "            neighbor_count += 1\n",
    "            neighbor_coordinates.append([x,y+1])\n",
    "            \n",
    "        if x < 4:\n",
    "            if probs[neighbor_count] < min_prob:\n",
    "                if not is_stuck and not self.visited_locations[f\"{x+1}{y}\"] or (is_stuck and not self.fully_explored_locations[f\"{x+1}{y}\"]):\n",
    "                    min_prob = probs[neighbor_count]\n",
    "                    is_left = False\n",
    "                    is_top = False\n",
    "                    is_right = True\n",
    "            neighbor_count += 1\n",
    "            neighbor_coordinates.append([x+1,y])\n",
    "            \n",
    "        if y > 1:\n",
    "            if probs[neighbor_count] < min_prob:\n",
    "                if not is_stuck and not self.visited_locations[f\"{x}{y-1}\"] or (is_stuck and not self.fully_explored_locations[f\"{x}{y-1}\"]):\n",
    "                    min_prob = probs[neighbor_count]\n",
    "                    is_left = False\n",
    "                    is_top = False\n",
    "                    is_right = False\n",
    "                    is_bottom = True\n",
    "            neighbor_count += 1\n",
    "            neighbor_coordinates.append([x,y-1])\n",
    "            \n",
    "        \n",
    "        location_to_go = []\n",
    "        if is_left:\n",
    "            location_to_go.append(x-1)\n",
    "            location_to_go.append(y)\n",
    "            \n",
    "        if is_top:\n",
    "            location_to_go.append(x)\n",
    "            location_to_go.append(y+1)\n",
    "            \n",
    "        if is_right:\n",
    "            location_to_go.append(x+1)\n",
    "            location_to_go.append(y)\n",
    "            \n",
    "        if is_bottom:\n",
    "            location_to_go.append(x)\n",
    "            location_to_go.append(y-1)\n",
    "            \n",
    "        remaining_neighbors = []\n",
    "        for coordinate in neighbor_coordinates:\n",
    "            if not (self.visited_locations[f\"{coordinate[0]}{coordinate[1]}\"] or self.wumpus_probs[self.get_index(coordinate[0],coordinate[1])] == 1 or\\\n",
    "                    (f\"{coordinate[0]}{coordinate[1]}\" in self.fully_explored_locations.keys() and self.fully_explored_locations[f\"{coordinate[0]}{coordinate[1]}\"])):\n",
    "                remaining_neighbors.append(coordinate)\n",
    "                \n",
    "        # We are leaving to the last available location from the original location, so let's mark the original as fully explored\n",
    "        if len(remaining_neighbors) == 1 and location_to_go in remaining_neighbors:\n",
    "            self.fully_explored_locations[f\"{x}{y}\"] = True\n",
    "            \n",
    "        return location_to_go\n",
    "    \n",
    "    def how_to_go(self, x, y, orientation, destination):\n",
    "        actions_to_take = []\n",
    "        if destination[0] > x:\n",
    "            if orientation == Orientation.N:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.S:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.E:\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.W:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "        elif destination[0] < x:\n",
    "            if orientation == Orientation.N:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.S:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.E:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.W:\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "        elif destination[1] > y:\n",
    "            if orientation == Orientation.N:\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.S:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.E:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.W:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "        elif destination[1] < y:\n",
    "            if orientation == Orientation.N:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.S:\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.E:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "            elif orientation == Orientation.W:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.FORWARD)\n",
    "        return actions_to_take\n",
    "    \n",
    "\n",
    "    def to_shoot_wumpus(self, x, y, orientation):\n",
    "        actions_to_take = []\n",
    "        if orientation == Orientation.W:\n",
    "            if x > 1 and self.wumpus_probs[self.get_index(x-1, y)] >= 0.5:\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y < 4 and self.wumpus_probs[self.get_index(x,y+1)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x < 4 and self.wumpus_probs[self.get_index(x+1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y > 1 and self.wumpus_probs[self.get_index(x,y-1)] >= 0.5:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "        elif orientation == Orientation.N:\n",
    "            if y < 4 and self.wumpus_probs[self.get_index(x,y+1)] >= 0.5:\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x < 4 and self.wumpus_probs[self.get_index(x+1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y > 1 and self.wumpus_probs[self.get_index(x,y-1)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x > 1 and self.wumpus_probs[self.get_index(x-1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "        elif orientation == Orientation.E:\n",
    "            if x < 4 and self.wumpus_probs[self.get_index(x+1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y > 1 and self.wumpus_probs[self.get_index(x,y-1)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x > 1 and self.wumpus_probs[self.get_index(x-1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y < 4 and self.wumpus_probs[self.get_index(x,y+1)] >= 0.5:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "        elif orientation == Orientation.S:\n",
    "            if y > 1 and self.wumpus_probs[self.get_index(x,y-1)] >= 0.5:\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x > 1 and self.wumpus_probs[self.get_index(x-1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif y < 4 and self.wumpus_probs[self.get_index(x,y+1)] >= 0.5:\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.RIGHT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "            elif x < 4 and self.wumpus_probs[self.get_index(x+1,y)] >= 0.5:\n",
    "                actions_to_take.append(Action.LEFT)\n",
    "                actions_to_take.append(Action.SHOOT)\n",
    "        return actions_to_take\n",
    "    \n",
    "\n",
    "    def run(self):\n",
    "        env = Environment()\n",
    "        cumulative_reward = 0\n",
    "        percept = env.init(0.2, True)\n",
    "        was_forward = False\n",
    "        was_shoot = False\n",
    "        while not percept.done:\n",
    "            if was_shoot:\n",
    "                if percept.scream:\n",
    "                    self.wumpus_alert = False\n",
    "                    for i in range(len(self.wumpus_probs)):\n",
    "                        self.wumpus_probs[i] = 0\n",
    "                else:\n",
    "                    if env.agent_orientation == Orientation.W and env.agent_location.x > 1:\n",
    "                        self.wumpus_probs[self.get_index(env.agent_location.x-1, env.agent_location.y)] = 0\n",
    "                    elif env.agent_orientation == Orientation.N and env.agent_location.y < 4:\n",
    "                        self.wumpus_probs[self.get_index(env.agent_location.x, env.agent_location.y+1)] = 0\n",
    "                    elif env.agent_orientation == Orientation.E and env.agent_location.x < 4:\n",
    "                        self.wumpus_probs[self.get_index(env.agent_location.x+1, env.agent_location.y)] = 0\n",
    "                    elif env.agent_orientation == Orientation.S and env.agent_location.y > 1:\n",
    "                        self.wumpus_probs[self.get_index(env.agent_location.x, env.agent_location.y-1)] = 0\n",
    "                    \n",
    "                    \n",
    "                    for i in range(len(self.wumpus_probs)):\n",
    "                        if self.wumpus_probs[i] != 0:\n",
    "                            self.wumpus_probs[i] = 1\n",
    "                \n",
    "                if f\"{env.agent_location.x}{env.agent_location.y}\" in self.fully_explored_locations.keys() and \\\n",
    "                            self.fully_explored_locations[f\"{env.agent_location.x}{env.agent_location.y}\"]:\n",
    "                        self.fully_explored_locations[f\"{env.agent_location.x}{env.agent_location.y}\"] = False\n",
    "                        \n",
    "            # Pits-Breezes\n",
    "            self.update_breeze(env.agent_location.x, env.agent_location.y, percept, env.agent_location.get_edge_count())\n",
    "            self.breeze_model = self.build_bayesian_network(env.agent_location.x, env.agent_location.y)\n",
    "            self.pit_probs = self.query_network(self.build_query(env.agent_location.x, env.agent_location.y, percept))\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print(\"Breeze Probs: \", self.pit_probs)\n",
    "                \n",
    "            # Wumpus-Stenches\n",
    "            self.update_stenches(env.agent_location.x, env.agent_location.y, percept)\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print(\"Stench Probs: \", self.wumpus_probs)\n",
    "            \n",
    "            self.get_neighbors_probs(env.agent_location.x, env.agent_location.y)\n",
    "            \n",
    "            action = None\n",
    "            self.add_new_nodes(Location(env.agent_location.x, env.agent_location.y), was_forward, env.agent_orientation)\n",
    "            if self.verbosity == Verbosity.ALL:\n",
    "                env.visualize()\n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print('Percept:', percept)\n",
    "            if len(self.actions_to_victory):\n",
    "                action = self.actions_to_victory.pop(0)\n",
    "            else:\n",
    "                if percept.glitter and not self.has_gold:\n",
    "                    action = Action.GRAB\n",
    "                    self.has_gold = True\n",
    "                    target_node = Node(Location(1, 1), Orientation.W)\n",
    "                    current_node = Node(env.agent_location, env.agent_orientation)\n",
    "                    self.find_actions_to_victory(current_node, networkx.astar_path(self.graph, current_node, target_node, heuristic=self.manhattan_distance))\n",
    "                elif self.has_gold and env.agent_location.is_location(Location(1,1)):\n",
    "                    action = Action.CLIMB\n",
    "                else:\n",
    "                    destination = self.where_to_go(env.agent_location.x, env.agent_location.y, self.get_neighbors_probs(env.agent_location.x, env.agent_location.y))\n",
    "                    if not len(destination):\n",
    "                        destination = self.where_to_go(env.agent_location.x, env.agent_location.y, self.get_neighbors_probs(env.agent_location.x, env.agent_location.y), True)  \n",
    "                    if self.wumpus_alert and env.wumpus_alive and env.agent_has_arrow:\n",
    "                        self.actions_to_victory = self.to_shoot_wumpus(env.agent_location.x, env.agent_location.y, env.agent_orientation)\n",
    "                        action = self.actions_to_victory.pop(0)\n",
    "                    else:\n",
    "                        if not len(destination):\n",
    "                            target_node = Node(Location(1, 1), Orientation.W)\n",
    "                            current_node = Node(env.agent_location, env.agent_orientation)\n",
    "                            self.find_actions_to_victory(current_node, networkx.astar_path(self.graph, current_node, target_node, heuristic=self.manhattan_distance))\n",
    "                        else:\n",
    "                            self.actions_to_victory = self.how_to_go(env.agent_location.x, env.agent_location.y, env.agent_orientation, destination)\n",
    "\n",
    "                        if not len(self.actions_to_victory):\n",
    "                            action = Action.CLIMB\n",
    "                        else:\n",
    "                            action = self.actions_to_victory.pop(0)\n",
    "            \n",
    "            if self.verbosity != Verbosity.NONE:\n",
    "                print()\n",
    "                print('Action:', action)\n",
    "                print()\n",
    "            percept = env.step(action)\n",
    "            if action == Action.FORWARD and not percept.bump:\n",
    "                was_forward = True\n",
    "            else:\n",
    "                was_forward = False\n",
    "            if action == Action.SHOOT:\n",
    "                was_shoot = True\n",
    "            else:\n",
    "                was_shoot = False\n",
    "            cumulative_reward += percept.reward\n",
    "        if self.verbosity == Verbosity.ALL:\n",
    "            env.visualize()\n",
    "            self.draw_graph()\n",
    "        if self.verbosity != Verbosity.NONE:\n",
    "            print('Percept:', percept)\n",
    "        print('Cumulative reward:', cumulative_reward)\n",
    "        return cumulative_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356e9e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alinakurliantseva/anaconda3/lib/python3.11/site-packages/torch/masked/maskedtensor/core.py:156: UserWarning: The PyTorch API of MaskedTensors is in prototype stage and will change in the near future. Please open a Github issue for features requests and see our documentation on the torch.masked module for further information about the project.\n",
      "  warnings.warn((\"The PyTorch API of MaskedTensors is in prototype stage \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative reward: -13\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 955\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -44\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 973\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -48\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: 978\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -41\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -41\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -26\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: 956\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 986\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -25\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: 953\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -48\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -32\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 952\n",
      "Cumulative reward: -39\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 954\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 960\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 958\n",
      "Cumulative reward: -44\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: 964\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -41\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 965\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -29\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -20\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 964\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 973\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 961\n",
      "Cumulative reward: -50\n",
      "Cumulative reward: 965\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: 977\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: 955\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 973\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 960\n",
      "Cumulative reward: 986\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -48\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: 960\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: 963\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -44\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 977\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -20\n",
      "Cumulative reward: -44\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -21\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 964\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -32\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -21\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -26\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 954\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: 961\n",
      "Cumulative reward: -37\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -45\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -21\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: 978\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: 950\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: 977\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 978\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: 961\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -46\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: 958\n",
      "Cumulative reward: -41\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -21\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 948\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -32\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -37\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: 986\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -32\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -20\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -30\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -25\n",
      "Cumulative reward: -45\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -35\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 965\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 977\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -21\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -48\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: 983\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: 963\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -25\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: 989\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -23\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 964\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 986\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 963\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -48\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 980\n",
      "Cumulative reward: 960\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 965\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 959\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 986\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 967\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -29\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 961\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: 977\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 982\n",
      "Cumulative reward: 965\n",
      "Cumulative reward: -45\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -45\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: -44\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 968\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: 973\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 958\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: -47\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: 970\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 971\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -31\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: 972\n",
      "Cumulative reward: 953\n",
      "Cumulative reward: 969\n",
      "Cumulative reward: 981\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -37\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: 974\n",
      "Cumulative reward: -35\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -27\n",
      "Cumulative reward: -19\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 964\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -40\n",
      "Cumulative reward: -36\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 957\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 962\n",
      "Cumulative reward: -41\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -43\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: 991\n",
      "Cumulative reward: -16\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -34\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -28\n",
      "Cumulative reward: -39\n",
      "Cumulative reward: -17\n",
      "Cumulative reward: 953\n",
      "Cumulative reward: -25\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 966\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: 979\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -11\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -42\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 954\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -29\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: -2\n",
      "Cumulative reward: 988\n",
      "Cumulative reward: -13\n",
      "Cumulative reward: -22\n",
      "Cumulative reward: 985\n",
      "Cumulative reward: 975\n",
      "Cumulative reward: 993\n",
      "Cumulative reward: -24\n",
      "Cumulative reward: -38\n",
      "Cumulative reward: -19\n",
      "GRAND TOTAL AVERAGE:  295.042\n"
     ]
    }
   ],
   "source": [
    "# Verbosity has 3 levels, NONE will show only the cumulative score, LOGS will show the percept logs\n",
    "# ALL will show both visualization and logs together.\n",
    "total_score = 0\n",
    "#ProbAgent(Verbosity.ALL).run()\n",
    "for i in range(1000):\n",
    "    total_score += ProbAgent(Verbosity.NONE).run()\n",
    "print(\"GRAND TOTAL AVERAGE: \", total_score/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4c8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
